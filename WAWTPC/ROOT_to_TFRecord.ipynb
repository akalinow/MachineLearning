{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 15:39:56.562711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os.path import isfile\n",
    "import io_functions as io\n",
    "\n",
    "\n",
    "from tensorflow.data import Dataset, TFRecordDataset\n",
    "from tensorflow.io import TFRecordWriter, TFRecordOptions\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize(charge_array, target):\n",
    "  feature = {'myChargeArray' : _bytes_feature(tf.io.serialize_tensor(charge_array)),\n",
    "             'target' : _bytes_feature(tf.io.serialize_tensor(target))}\n",
    "  example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example.SerializeToString()\n",
    "\n",
    "def conversion(filename, queue):\n",
    "    options = TFRecordOptions(compression_type='GZIP')\n",
    "    writer = TFRecordWriter(filename, options=options)\n",
    "    while True:\n",
    "        item = queue.get()\n",
    "        if item == None:\n",
    "            break\n",
    "        charge_array, target = item\n",
    "        charge_array= io.proc_features(charge_array)\n",
    "        \n",
    "        example = serialize(charge_array, target)\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/scratch/szslaw/'\n",
    "input_files = [dataPath+'out_random_sigma2k2mm.root:TPCData']\n",
    "batchSize = 5\n",
    "nFiles = 5 # number of output files, equal to number of processes\n",
    "\n",
    "datasetGenerator = io.minimal_generator(files=input_files, batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process-1 started\n",
      "Process-2 started\n",
      "Process-3 started\n",
      "Process-4 started\n",
      "Process-5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 15:41:24.592641: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "2023-11-21 15:41:24.748360: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "2023-11-21 15:41:24.898134: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "2023-11-21 15:41:24.964491: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "2023-11-21 15:41:25.081353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 100 batches\n",
      "read 200 batches\n",
      "read 300 batches\n",
      "read 400 batches\n",
      "Process-1 done\n",
      "Process-2 done\n",
      "Process-3 done\n",
      "Process-4 done\n",
      "Process-5 done\n",
      "CPU times: user 34 s, sys: 19.8 s, total: 53.9 s\n",
      "Wall time: 45.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_files = [dataPath + 'test/' + f\"out_random_sigma2k2mm-part-{i}.tfrecord\" for i in range(nFiles)]\n",
    "\n",
    "for file in output_files:\n",
    "    if isfile(file):\n",
    "        raise Exception('output file already exists')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    processes = []\n",
    "    q = Queue(2*nFiles)\n",
    "    \n",
    "    for name in output_files:\n",
    "        p = Process(target=conversion, args=(name, q))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "        print(p.name + ' started')\n",
    "\n",
    "    counter = 0\n",
    "    for item in datasetGenerator:\n",
    "        q.put(item)\n",
    "        counter+=1\n",
    "        if counter%100 == 0:\n",
    "            print(f'read {counter} batches')\n",
    "\n",
    "    for _ in range(nFiles):\n",
    "        q.put(None)\n",
    "    \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        print(p.name + ' done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [dataPath +\"folder/\"+ f\"out_random_sigma-001-part-{i}.tfrecord\" for i in range(5)]\n",
    "train_dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP', num_parallel_reads=5)\n",
    "test_dataset = tf.data.TFRecordDataset(dataPath +\"folder/\"+'out_random_sigma2k2mm.tfrecord', compression_type='GZIP')\n",
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'myChargeArray': tf.io.FixedLenFeature([], tf.string),\n",
    "    'target': tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    charge, target = parsed_features['myChargeArray'], parsed_features['target']\n",
    "    # decode from bytes\n",
    "    charge = tf.io.parse_tensor(charge, tf.float64)\n",
    "    target = tf.io.parse_tensor(target, tf.float64)\n",
    "    \n",
    "    return charge, target\n",
    "\n",
    "def shape_items(charge, target):\n",
    "    charge.set_shape(charge_shape)\n",
    "    target.set_shape(target_shape)\n",
    "    return charge, target\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.unbatch()\n",
    "test_dataset = test_dataset.unbatch()\n",
    "\n",
    "train_dataset = train_dataset.batch(batchSize)\n",
    "test_dataset = test_dataset.batch(batchSize)\n",
    "\n",
    "for charge, target in train_dataset.take(1):\n",
    "    charge_shape = charge.shape\n",
    "    target_shape = target.shape\n",
    "\n",
    "    train_dataset = train_dataset.map(shape_items)\n",
    "    test_dataset = test_dataset.map(shape_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
