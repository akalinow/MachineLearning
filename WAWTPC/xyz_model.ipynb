{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime  \n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "import io_functions as io\n",
    "import plotting_functions as plf\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Description\n",
    "The data used for training the model was generated in numerical simulations in the .root format. It was then converted to the .tfrecord format using the `ROOT_to_TFRecord.ipynb` notebook and the `conversion_xyz` function.\n",
    "\n",
    "This notebook presents the xyz reconstruction approach, where the model takes all three projections in uvwt coordinates and performs reconstruction to obtain the xyz coordinates of an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"/scratch/pszyc\"\n",
    "batchSize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f\"{dataPath}/data_xyz/out_random_sigma-001-part-{i}.tfrecord\" for i in range(5)]\n",
    "train_dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP', num_parallel_reads=5)\n",
    "test_dataset = tf.data.TFRecordDataset(f\"{dataPath}/data_xyz/out_random_sigma2k2mm-part-0.tfrecord\", compression_type='GZIP')\n",
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'myChargeArray': tf.io.FixedLenFeature([], tf.string),\n",
    "    'target': tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    charge, target = parsed_features['myChargeArray'], parsed_features['target']\n",
    "    # decode from bytes\n",
    "    charge = tf.io.parse_tensor(charge, tf.float64)\n",
    "    target = tf.io.parse_tensor(target, tf.float64)\n",
    "    \n",
    "    return charge, target\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.unbatch()\n",
    "test_dataset = test_dataset.unbatch()\n",
    "\n",
    "train_dataset = train_dataset.batch(batchSize)\n",
    "test_dataset = test_dataset.batch(batchSize)\n",
    "\n",
    "for aBatch in train_dataset.take(1):\n",
    "    plf.plotEvent(aBatch, model=None)\n",
    "    pass\n",
    "\n",
    "for aBatch in test_dataset.take(1):\n",
    "    plf.plotEvent(aBatch, model=None)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = regularizers.l2(0.01)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape = (256, 512, 3)), \n",
    "    tf.keras.layers.Conv2D(16, 5, padding='same', activation='relu', data_format=\"channels_last\", input_shape=(256, 512, 1), kernel_regularizer=regularizer),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(32, 5, padding='same', activation='relu', data_format=\"channels_last\", kernel_regularizer=regularizer),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(64, 5, padding='same', activation='relu', data_format=\"channels_last\", kernel_regularizer=regularizer),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizer),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizer),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizer),\n",
    "    tf.keras.layers.Dense(9)\n",
    "])\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                decay_steps=5000,\n",
    "                decay_rate=0.98,\n",
    "                staircase=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule) \n",
    "model.compile(optimizer = optimizer, \n",
    "              loss = 'mse', \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=(10, 20))\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=5, verbose=1)\n",
    "callbacks =  [early_stop_callback, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs=epochs,\n",
    "                    workers = 3,\n",
    "                    use_multiprocessing = True,\n",
    "                    validation_data = test_dataset.take(10),\n",
    "                    callbacks=callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "\n",
    "job_dir = f\"{dataPath}/{epochs:04d}_\"+current_time\n",
    "model.save(job_dir.format(epochs=epochs), save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance\n",
    "\n",
    "Fill Pandas DataFrame with true and response values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility_functions as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Inference. Current Time =\", current_time)\n",
    "\n",
    "#model_path = \"./training/2023_Apr_28_16_58_32/\"\n",
    "#model_path = \"/scratch_hdd/akalinow/ELITPC/PythonAnalysis/training/2023_May_02_23_51_30/\"\n",
    "#model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "df = utils.df\n",
    "\n",
    "for aBatch in test_dataset: \n",
    "    df = utils.fillPandasDataset(aBatch, df, model)     \n",
    "    \n",
    "for aBatch in test_dataset.take(5):\n",
    "    plf.plotEvent(aBatch, model=model)\n",
    "\n",
    "df.describe()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting_functions as plf\n",
    "importlib.reload(plf)\n",
    "\n",
    "#plf.controlPlots(df)\n",
    "plf.plotEndPointRes(df=df, edge=\"Start\", partIdx=1)\n",
    "plf.plotEndPointRes(df=df, edge=\"Stop\", partIdx=1)\n",
    "\n",
    "plf.plotEndPointRes(df=df, edge=\"Start\", partIdx=2)\n",
    "plf.plotEndPointRes(df=df, edge=\"Stop\", partIdx=2)\n",
    "\n",
    "plf.plotLengthPull(df, partIdx=1)\n",
    "plf.plotLengthPull(df, partIdx=2)\n",
    "plf.plotLengthPullEvolution(df)\n",
    "plf.plotOpeningAngleCos(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
